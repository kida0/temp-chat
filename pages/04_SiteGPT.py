# # https://openai.com/sitemap.xml sitemapì„ ì‚¬ìš©í•´ì„œ ì›¹ ì‚¬ì´íŠ¸ì— ì¡´ì¬í•˜ëŠ” ëª¨ë“  pageì˜ urlì„ ì°¾ì•„ë‚¼ ìˆ˜ ìˆìŒ
# # playwright: ë¸Œë¼ìš°ì € ì»¨íŠ¸ë¡¤ì„ í•  ìˆ˜ ìˆëŠ” íŒ¨í‚¤ì§€(seleniumê³¼ ë¹„ìŠ·)
# # chronium
# # playwright install: ì„¤ì¹˜ ë°©ì‹ì´ ì¢€ íŠ¹ì´í•˜ë„¤
# # playwrightë¥¼ headless ëª¨ë“œë¡œ ì‹¤í–‰ -> headlessfks browser processê°€ ë‚´ ì»´í“¨í„°ë¡œë¶€í„° ì‹œì‘ë˜ëŠ” ê²ƒì„ ì˜ë¯¸
# # -> ì†ë„ê°€ ëŠë ¤ì§
# # ì›¹ ì‚¬ì´íŠ¸ ìŠ¤í¬ë©ì„ ë„ˆë¬´ ë¹ ë¥´ê²Œí•˜ë©´ ì°¨ë‹¨ë‹¹í•  ìˆ˜ ìˆìŒ... -> Sitemapì—ì„œëŠ” 1ì´ˆì— í•œ ë²ˆì”© í˜¸ì¶œ ìˆ˜í–‰
# # metadata ì €ì¥ë„ í™•ì¸ ê°€ëŠ¥ : metadata={'source': 'https://openai.com/research/weak-to-strong-generalization', 'loc': 'https://openai.com/research/weak-to-strong-generalization', 'lastmod': '2023-12-16T00:32:09.053Z', 'changefreq': 'daily', 'priority': '1.0'})
# # SitemapLoaderëŠ” ë‚´ë¶€ì ìœ¼ë¡œ beautiful soup ì‚¬ìš©
# # vector storeë¥¼ ë§Œë“¤ì–´ì„œ ì—°ê´€ ìˆëŠ” docuë¥¼ ê²€ìƒ‰
# # llmì—ê²Œ ë‹µë³€ì˜ ìœ ìš©í•¨ í‰ê°€ ìš”ì²­


# import streamlit as st
# from langchain.document_loaders import AsyncChromiumLoader
# from langchain.document_transformers import Html2TextTransformer
# from langchain.document_loaders import SitemapLoader
# from langchain.text_splitter import RecursiveCharacterTextSplitter
# from langchain.vectorstores.faiss import FAISS
# from langchain.embeddings import OpenAIEmbeddings
# from langchain.schema.runnable import RunnablePassthrough, RunnableLambda
# from langchain.chat_models import ChatOpenAI
# from langchain.prompts import ChatPromptTemplate



# st.set_page_config(
#     page_title="SiteGPT",
#     page_icon="ğŸ‹",
# )

# st.title("SiteGPT")
# st.markdown(
#     """
#     Ask question about the content of a website
    
#     Start by writing the URL of the website on the sidebar
#     """
# )

# # htmlì„ ë°›ì•„ì„œ textë¡œ ë³€í™˜
# html2text_transformer = Html2TextTransformer()


# # ì‚¬ì´ë“œë°” ì…ë ¥ ì¹¸ ìƒì„±
# with st.sidebar:
#     url = st.text_input(
#         "Write down a URL", 
#         placeholder="https://example.com",
#         )


# # ì‚¬ì´ë“œë°”ì— urlì„ ì…ë ¥í•˜ë©´, í•´ë‹¹ í˜ì´ì§€ì˜ htmlì„ ì½ì–´ì˜´
# # if url:
# #     # async chromium loader
# #     loader = AsyncChromiumLoader([url])
# #     docs = loader.load()
# #     transformed = html2text_transformer.transform_documents(docs)
# #     st.write(docs)

# # SitemapLoader ì‚¬ìš©
# # if url:
# #     if ".xml" not in url:
# #         with st.sidebar:
# #             st.error("Please write down a Sitemap URL.")
# #     else:
# #         loader = SitemapLoader(url)
# #         # loader.requests_per_second = 1
# #         docs = loader.load()
# #         st.write(docs)

 
# llm = ChatOpenAI(
#     temperature=0.1,
# )

# answers_prompt = ChatPromptTemplate.from_template(
#     """
#         Using ONLY the following context answer the user's question. If you can't just say you don't know, don't make anything up.
                                                    
#         Then, give a score to the answer between 0 and 5.
#         If the answer answers the user question the score should be high, else it should be low.
#         Make sure to always include the answer's score even if it's 0.
#         Context: {context}
                                                    
#         Examples:
                                                    
#         Question: How far away is the moon?
#         Answer: The moon is 384,400 km away.
#         Score: 5
                                                    
#         Question: How far away is the sun?
#         Answer: I don't know
#         Score: 0
                                                    
#         Your turn!
#         Question: {question}
#     """
# )


# # soupì€ beautifule soup objectë¡œ ëœ html ë©ì–´ë¦¬ë¡œ ê²€ìƒ‰ì´ë‚˜ ì‚­ì œ ì‘ì—… ìˆ˜í–‰ ê°€ëŠ¥
# def parse_page(soup):
#     header = soup.find("header")
#     footer = soup.find("footer")
#     if header:
#         header.decompose()  # decompose: ì œê±°
#     if footer:
#         footer.decompose()
#     return (
#         str(soup.get_text())
#         .replace("\n", " ")
#         .replace("\xa0", " ")
#         .replace("ClosingSearch Submit Blog", "")
#     )
    
    
# # ìºì‹±ë˜ëŠ”, urlì˜ í…ìŠ¤íŠ¸ë§Œ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜ 
# @st.cache_data(show_spinner="Loading website...")
# def load_website(url):
#     # splitterë¥¼ ì •ì˜í•˜ì—¬ load_and_splitì™€ í•¨ê»˜ ì‚¬ìš© ê°€ëŠ¥
#     splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(
#         chunk_size=1000,
#         chunk_overlap=200,
#     )

#     loader = SitemapLoader(
#         url,
#         # filter_urls=["http://openai.com/blog/data-par..."],  # ì§ì ‘ì ìœ¼ë¡œ ì£¼ì†Œë¥¼ ì¤„ ìˆ˜ë„ ìˆê³ 
#         # filter_urls=[r"^(?!.*\/blog\/).*"],  # ì •ê·œí‘œí˜„ì‹ë„ ì‚¬ìš© ê°€ëŠ¥(exclude /blog/)
#         # filter_urls=[r"^(.*\/blog\/).*"],  # ì •ê·œí‘œí˜„ì‹ë„ ì‚¬ìš© ê°€ëŠ¥(include /blog/)
#         parsing_function=parse_page
#     )
#     loader.requests_per_second = 2
#     # docs = loader.load()
#     docs = loader.load_and_split(text_splitter=splitter)
#     vector_score = FAISS.from_documents(docs,OpenAIEmbeddings())
#     return vector_score.as_retriever()


# choose_prompt = ChatPromptTemplate.from_messages(
#     [
#         (
#             "system",
#             """
#             Use ONLY the following pre-existing answers to answer the user's question.
#             Use the answers that have the highest score (more helpful) and favor the most recent ones.
#             Cite sources and return the sources of the answers as they are, do not change them.
#             Answers: {answers}
#             """,
#         ),
#         ("human", "{question}"),
#     ]
# )


# def choose_answer(inputs):
#     answers = inputs["answers"]
#     question = inputs["question"]
#     choose_chain = choose_prompt | llm
#     condensed = "\n\n".join(
#         f"Answer: {answer['answer']}\nSource:{answer['source']}\nDate:{answer['date']}" for answer in answers
#     )
#     return choose_chain.invoke({
#         "question": question,
#         "answers": condensed
#     })


# def get_answers(inputs):
#     docs = inputs["docs"]
#     question = inputs["question"]
#     answers_chain = answers_prompt | llm
#     # answers = []
#     # for doc in docs:
#     #     result = answers_chain.invoke({
#     #         "question": question,
#     #         "context": doc.page_content
#     #     })
#     #     answers.append(result.content)
#     # st.write(answers)
#     return {
#         "question": question, 
#         "answers": [
#             {
#                 "answer": answers_chain.invoke(
#                     {"question": question, "context": doc.page_content}
#                 ).content,
#                 "source": doc.metadata["source"],
#                 "date": doc.metadata["lastmod"],
#             } for doc in docs
#         ]
#     }


# if url:
#     if ".xml" not in url:
#         with st.sidebar:
#             st.error("Please write down a Sitemap URL.")
#     else:
#         retriever = load_website(url)
#         query = st.text_input("Ask a question to the websie.")
#         if query:
#             chain = {
#                 "docs": retriever, 
#                 "question": RunnablePassthrough(),
#             } | RunnableLambda(get_answers) | RunnableLambda(choose_answer)
            
#             result = chain.invoke(query)
#             st.write(result.content)